#install.packages("conStruct",dep=T)
.libPaths()
library(conStruct)

## Load data
load("temp/urcAA.2_construct_pop_data.rda",verbose=TRUE)
str(urc.data)
pops=rownames(urc.data$allele.frequencies)

conStruct(spatial = TRUE,K = 2,freqs = urc.data$allele.frequencies,
          coords = urc.data$coords,geoDist = urc.data$geoDist,
          prefix = "output/constructAA/K2_sp.2",n.iter = 1000, 
          control = list(adapt_delta = 0.99))

## replace line 13 with this to reduce warnings control = list(adapt_delta = .99,max_treedepth = 15)
###################################################################################
## Cross-validation
###################################################################################
## Cross validation tests how well models built on a subset of the data (the
#   training set) predict allele frequencies in a different subset (the validation
#   set). This prediction accuracy provides a measure of how well the model
#   fits the data. We repeat the cross-validation 8 times for each value of K.

## First set up a new directory, as conStruct doesn't like to overwrite files.
#   If the test1 directory already exists, you'll see an error message. To 
#   proceed, change run.name to test2 (or whatever you like!).
run.name="urcAA_xval_k5_i1e3"
rundir=file.path("output",run.name)
dir.create(rundir)

# to run a cross-validation analysis
# you have to specify:
#       the numbers of layers you want to compare (K)
#       the allele frequency data (freqs)
#       the geographic distance matrix (geoDist)
#       the sampling coordinates (coords)

x.validation(train.prop = 0.9,
             n.reps = 10,
             K = 1:5,
             freqs = urc.data$allele.frequencies,
             data.partitions = NULL,
             geoDist = urc.data$geoDist,
             coords = urc.data$coords,
             prefix = file.path(rundir,"urcAA"),
             n.iter = 1e3,
             make.figs = TRUE,
             save.files = TRUE,
             parallel = TRUE,
             n.nodes = 2)


# read in results from text files

sp.results <- as.matrix(
  read.table(file.path(run.name,"example_sp_xval_results.txt"),
             header = TRUE,
             stringsAsFactors = FALSE)
)
nsp.results <- as.matrix(
  read.table(file.path(run.name,"example_nsp_xval_results.txt"),
             header = TRUE,
             stringsAsFactors = FALSE)
)

# first, get the 95% confidence intervals for the spatial and nonspatial
#   models over values of K (mean +/- 1.96 the standard error)

sp.CIs <- apply(sp.results,1,function(x){mean(x) + c(-1.96,1.96) * sd(x)/length(x)})
nsp.CIs <- apply(nsp.results,1,function(x){mean(x) + c(-1.96,1.96) * sd(x)/length(x)})

# then, plot cross-validation results for K=1:3 with 8 replicates

par(mfrow=c(1,2))
plot(rowMeans(sp.results),
     pch=19,col="blue",
     ylab="predictive accuracy",xlab="values of K",
     ylim=range(sp.results,nsp.results),
     main="cross-validation results")
points(rowMeans(nsp.results),col="green",pch=19)

# finally, visualize results for the spatial model
#   separately with its confidence interval bars
#
# note that you could do the same with the spatial model, 
#   but the confidence intervals don't really show up 
#   because the differences between predictive accuracies
#   across values of K are so large.

yrange=range(sp.CIs[,-1])

plot(rowMeans(sp.results),
     pch=19,col="blue",
     ylab="predictive accuracy",xlab="values of K",
     ylim=yrange,
     main="spatial cross-validation results")
segments(x0 = 1:nrow(sp.results),
         y0 = sp.CIs[1,],
         x1 = 1:nrow(sp.results),
         y1 = sp.CIs[2,],
         col = "blue",lwd=2)

points(rowMeans(nsp.results),
       pch=19,col="green",
       ylab="predictive accuracy",xlab="values of K",
       ylim=yrange,
       main="nonspatial cross-validation results")
segments(x0 = 1:nrow(nsp.results),
         y0 = nsp.CIs[1,],
         x1 = 1:nrow(nsp.results),
         y1 = nsp.CIs[2,],
         col = "green",lwd=2)


###################################################################################
## Layer contributions
###################################################################################
# Layer contributions offer a second metric users can employ to compare models
#   with different numbers of layers


# Loop through output files generated by conStruct 
#   runs with K=1 through 5 and calculate the 
#   layer contributions for each layer in each run  

maxK=nrow(sp.results)
layer.contributions <- matrix(0,nrow=maxK,ncol=maxK)


# load the conStruct.results.Robj and data.block.Robj
#   files saved at the end of a conStruct run with K=1

load(file.path(run.name,"example_nsp_rep1K1_conStruct.results.Robj"))
load(file.path(run.name,"example_nsp_rep1K1_data.block.Robj"))

# calculate layer contributions
layer.contributions[1, 1] <-1
calculate.layer.contribution(conStruct.results[[1]], data.block)
tmp <- conStruct.results[[1]]$MAP$admix.proportions

layer.contributions.sp=layer.contributions

# First calculate and plot the layer contributions for the nonspatial model.
for (i in 2:maxK) {
  ## Non-spatial models
  # load the conStruct.results.Robj and data.block.Robj
  #   files saved at the end of a conStruct run
  load(file.path(run.name,paste0("example_nsp_rep1K",i,"_conStruct.results.Robj")))
  load(file.path(run.name,paste0("example_nsp_rep1K",i,"_data.block.Robj")))
  
  # match layers up across runs to keep plotting colors consistent
  #   for the same layers in different runs
  tmp.order <- match.layers.x.runs(tmp, conStruct.results[[1]]$MAP$admix.proportions)
  
  # calculate layer contributions
  layer.contributions[, i] <- c(calculate.layer.contribution(
    conStruct.results = conStruct.results[[1]],
    data.block = data.block,
    layer.order = tmp.order),
    rep(0, nrow(layer.contributions) - i))
  layer.contributions[, i]=layer.contributions[, i][order(layer.contributions[, i],decreasing = TRUE)]
  
  ## Spatial models
  # load the conStruct.results.Robj and data.block.Robj
  #   files saved at the end of a conStruct run
  load(file.path(run.name,paste0("example_sp_rep1K",i,"_conStruct.results.Robj")))
  load(file.path(run.name,paste0("example_sp_rep1K",i,"_data.block.Robj")))
  
  # match layers up across runs to keep plotting colors consistent
  #   for the same layers in different runs
  tmp.order <- match.layers.x.runs(tmp, conStruct.results[[1]]$MAP$admix.proportions)
  
  # calculate layer contributions
  layer.contributions.sp[, i] <- c(calculate.layer.contribution(
    conStruct.results = conStruct.results[[1]],
    data.block = data.block,
    layer.order = tmp.order),
    rep(0, nrow(layer.contributions.sp) - i))
  layer.contributions.sp[, i]=layer.contributions.sp[, i][order(layer.contributions.sp[, i],decreasing = TRUE)]
}

## Stacked barplot for nonspatial model
par(mfrow = c(1, 2))
barplot(layer.contributions,
        col=c("blue", "red", "goldenrod1", "forestgreen", "darkorchid1"),
        xlab="",
        ylab="layer contributions",
        names.arg=paste0("K=",1:maxK),
        main = "Nonspatial model")

barplot(layer.contributions.sp,
        col=c("blue", "red", "goldenrod1", "forestgreen", "darkorchid1"),
        xlab="",
        ylab="layer contributions",
        names.arg=paste0("K=",1:maxK),
        main = "Spatial model")



###################################################################################
## Runs for plots
###################################################################################

conStruct(spatial = TRUE,K = 2,freqs = urc.data$allele.frequencies,
          coords = urc.data$coords,geoDist = urc.data$geoDist,
          prefix = "K2_sp",n.iter = 10000)
conStruct(spatial = FALSE,K = 2,freqs = urc.data$allele.frequencies,
          coords = urc.data$coords,geoDist = urc.data$geoDist,
          prefix = "K2a",n.iter = 10000)
conStruct(spatial = FALSE,K = 2,freqs = urc.data$allele.frequencies,
          coords = urc.data$coords,geoDist = urc.data$geoDist,
          prefix = "K2b",n.iter = 10000)
conStruct(spatial = FALSE,K = 3,freqs = urc.data$allele.frequencies,
          coords = urc.data$coords,geoDist = urc.data$geoDist,
          prefix = "K3",n.iter = 10000)
conStruct(spatial = FALSE,K = 3,freqs = urc.data$allele.frequencies,
          coords = urc.data$coords,geoDist = urc.data$geoDist,
          prefix = "K3a",n.iter = 10000)
conStruct(spatial = FALSE,K = 3,freqs = urc.data$allele.frequencies,
          coords = urc.data$coords,geoDist = urc.data$geoDist,
          prefix = "K3b",n.iter = 10000)
conStruct(spatial = FALSE,K = 4,freqs = urc.data$allele.frequencies,
          coords = urc.data$coords,geoDist = urc.data$geoDist,
          prefix = "K4",n.iter = 10000)
conStruct(spatial = FALSE,K = 5,freqs = urc.data$allele.frequencies,
          coords = urc.data$coords,geoDist = urc.data$geoDist,
          prefix = "K5",n.iter = 10000)
conStruct(spatial = FALSE,K = 6,freqs = urc.data$allele.frequencies,
          coords = urc.data$coords,geoDist = urc.data$geoDist,
          prefix = "K6",n.iter = 10000)


## Examine the admixture proportions
load("K3_sp_conStruct.results.Robj")
conStruct.results$chain_1$MAP$admix.proportions

## and we can look at the rate of decay of covariance with distance in each layer
conStruct.results$chain_1$MAP$layer.params$layer_1$alphaD
conStruct.results$chain_1$MAP$layer.params$layer_2$alphaD
conStruct.results$chain_1$MAP$layer.params$layer_3$alphaD
